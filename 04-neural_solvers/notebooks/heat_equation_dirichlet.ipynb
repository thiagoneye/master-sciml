{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thiagoneye/master-sciml/blob/main/04-neural_solvers/notebooks/heat_equation_dirichlet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2f2OaiF0tO1"
      },
      "source": [
        "## PINN para a Equação do Calor 1D\n",
        "\n",
        "Este notebook implementa uma **Rede Neural Informada pela Física (PINN)** para resolver a Equação do Calor 1D.\n",
        "\n",
        "A abordagem combina o aprendizado supervisionado tradicional com a imposição de uma restrição física (a própria equação diferencial parcial), permitindo que a rede neural aprenda a solução do problema em todo o domínio espaço-tempo.\n",
        "\n",
        "### A Equação do Calor 1D Transiente\n",
        "\n",
        "A equação governante do fenômeno é:\n",
        "\n",
        "$$ \\frac{\\partial T}{\\partial t} = \\alpha \\frac{\\partial^2 T}{\\partial x^2} $$\n",
        "\n",
        "Onde:\n",
        "- $T$ é a temperatura.\n",
        "- $t$ é o tempo.\n",
        "- $x$ é a posição.\n",
        "- $\\alpha$ é a difusividade térmica do material (uma constante).\n",
        "\n",
        "A rede neural será treinada para aproximar a função $T(x, t)$. A função de perda total será uma combinação de:\n",
        "\n",
        "1.  **Perda de Dados (MSE):** O erro entre a previsão da rede e os dados de medição fornecidos.\n",
        "2.  **Perda da Física (Residual da PDE):** Uma medida de quanto a saída da rede viola a equação do calor.\n",
        "\n",
        "### Resumo do Procedimento\n",
        "\n",
        "1.  **Carregar e Preparar Dados**: Carregue seu `df` e crie tensores para as posições `(x, t)` e temperaturas `T`.\n",
        "2.  **Gerar Pontos de Colocação**: Crie um conjunto de pontos `(x, t)` aleatórios dentro do seu domínio para avaliar a perda da física.\n",
        "3.  **Definir o Modelo**: Crie uma rede neural sequencial com Keras que mapeia `(x, t)` para `T`.\n",
        "4.  **Implementar as Funções de Perda**:\n",
        "    - `data_loss`: MSE entre as previsões e os dados reais.\n",
        "    - `physics_loss`: MSE do residual da PDE, calculado usando `tf.GradientTape` para obter as derivadas.\n",
        "5.  **Criar o Loop de Treinamento**:\n",
        "    - Em cada época, calcule a perda de dados e a perda da física.\n",
        "    - Some-as para obter a perda total.\n",
        "    - Use `tf.GradientTape` para encontrar os gradientes da perda total em relação aos pesos do modelo.\n",
        "    - Aplique esses gradientes usando um otimizador como o Adam.\n",
        "6.  **Treinar e Avaliar**: Execute o loop por um número suficiente de épocas e, ao final, use o `pinn_model` treinado para fazer previsões e visualizar a solução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i5M3LKz1ETe"
      },
      "source": [
        "### Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9KovTdDyPgu",
        "outputId": "5544f778-70ac-4258-ba63-979cdea24268"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "tf.keras.backend.set_floatx(\"float64\")\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "print(f\"Número de GPUs disponíveis: {len(gpus)}\")\n",
        "if gpus:\n",
        "    print(\"A GPU está sendo utilizada pelo TensorFlow.\")\n",
        "    print(\"Detalhes da GPU:\", gpus)\n",
        "else:\n",
        "    print(\"O TensorFlow NÃO encontrou a GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxT_XacE1Lfs"
      },
      "source": [
        "### Leitura e Preparação dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "SWAW3rqnyeCI",
        "outputId": "de8d2eaf-d25c-4d36-9fc2-7955c2264b90"
      },
      "outputs": [],
      "source": [
        "# Parâmetros do problema\n",
        "ALPHA = 0.5\n",
        "\n",
        "# Leitura dos dados\n",
        "df_full = pd.read_csv(\"heat_equation_dirichlet.csv\")\n",
        "\n",
        "# Dados completos, entrada (x, t) e saída (T)\n",
        "X = df_full[[\"time\", \"position\"]].values\n",
        "T = df_full[[\"temperature\"]].values\n",
        "\n",
        "# Dados de treino\n",
        "df = df_full[\n",
        "    (df_full[\"time\"] == 0) | (df_full[\"position\"] == 0) | (df_full[\"position\"] == 1)\n",
        "]\n",
        "df = df.sample(frac=0.665, random_state=42)\n",
        "\n",
        "X_train_raw = df[[\"time\", \"position\"]].values\n",
        "T_train_raw = df[[\"temperature\"]].values\n",
        "\n",
        "# Converte para tensores do TensorFlow\n",
        "X_train_tf = tf.convert_to_tensor(X_train_raw, dtype=tf.float64)\n",
        "T_train_tf = tf.convert_to_tensor(T_train_raw, dtype=tf.float64)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(6, 3))\n",
        "ax.scatter(X_train_raw[:, 0], X_train_raw[:, 1], alpha=0.3, label=f\"{len(df)} pontos\")\n",
        "ax.set_title(\"Pontos de Treinamento\", fontsize=14)\n",
        "ax.set_xlabel(\"Tempo (t)\", fontsize=10)\n",
        "ax.set_ylabel(\"Posição (x)\", fontsize=10)\n",
        "ax.legend()\n",
        "plt.savefig(\"../results/dirichlet_condition/training_points.png\", dpi=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C11cA161ReG"
      },
      "source": [
        "### Geração dos Pontos de Colocação\n",
        "\n",
        "Estes são os pontos no interior do domínio onde não conhecemos a temperatura. Eles serão usados para calcular a **perda da física** ($L_{física}$), forçando a rede a obedecer à equação do calor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "PaAyx7c5zqyV",
        "outputId": "5dc6558c-b718-4654-9678-df33ac1464b8"
      },
      "outputs": [],
      "source": [
        "N_collocation = 20000\n",
        "\n",
        "# Pega os limites do domínio a partir dos dados\n",
        "t_min, t_max = df_full[\"time\"].min(), df_full[\"time\"].max()\n",
        "x_min, x_max = df_full[\"position\"].min(), df_full[\"position\"].max()\n",
        "\n",
        "# Gera pontos aleatórios dentro desses limites\n",
        "x_collocation = tf.random.uniform(\n",
        "    (N_collocation, 1), minval=x_min, maxval=x_max, dtype=tf.float64\n",
        ")\n",
        "t_collocation = tf.random.uniform(\n",
        "    (N_collocation, 1), minval=t_min, maxval=t_max, dtype=tf.float64\n",
        ")\n",
        "\n",
        "X_collocation_raw = tf.concat([t_collocation, x_collocation], axis=1)\n",
        "X_collocation_tf = tf.convert_to_tensor(X_collocation_raw, dtype=tf.float64)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(6, 3))\n",
        "ax.scatter(\n",
        "    X_collocation_raw[:, 0],\n",
        "    X_collocation_raw[:, 1],\n",
        "    alpha=0.3,\n",
        "    label=f\"{N_collocation} pontos\",\n",
        ")\n",
        "ax.set_title(\"Pontos de Colocação\", fontsize=14)\n",
        "ax.set_xlabel(\"Tempo (t)\", fontsize=10)\n",
        "ax.set_ylabel(\"Posição (x)\", fontsize=10)\n",
        "ax.legend()\n",
        "plt.savefig(\"../results/dirichlet_condition/placement_points.png\", dpi=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3xqvKwC1j6f"
      },
      "source": [
        "### Construção do Modelo (Rede Neural)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "a4Tte_El0Tvo",
        "outputId": "7a074c19-01d8-4cb2-d84c-c15eeb5cc2e4"
      },
      "outputs": [],
      "source": [
        "def create_pinn_model(num_hidden_layers=10, num_neurons=64):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=(2,)))\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        model.add(tf.keras.layers.Dense(num_neurons, activation=\"tanh\"))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1, activation=None))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "pinn_model = create_pinn_model()\n",
        "pinn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHtWLOl1g97"
      },
      "source": [
        "### Função de Perda Híbrida\n",
        "\n",
        "A função de perda total é a soma da perda nos dados e da perda na física. Aqui, implementamos o cálculo do resíduo da EDP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxQfacxF1xyq"
      },
      "outputs": [],
      "source": [
        "def data_loss(model, X_data, T_data):\n",
        "    T_pred = model(X_data)\n",
        "    return tf.reduce_mean(tf.square(T_pred - T_data))\n",
        "\n",
        "\n",
        "def physics_loss(model, t, x, ALPHA):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        tape.watch(t)\n",
        "        tape.watch(x)\n",
        "\n",
        "        X_concat = tf.concat([t, x], axis=1)\n",
        "        T_pred = model(X_concat)\n",
        "\n",
        "        dT_dx = tape.gradient(T_pred, x)\n",
        "\n",
        "    dT_dt = tape.gradient(T_pred, t)\n",
        "    d2T_dx2 = tape.gradient(dT_dx, x)\n",
        "\n",
        "    del tape\n",
        "\n",
        "    residual = dT_dt - ALPHA * d2T_dx2\n",
        "    return tf.reduce_mean(tf.square(residual))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naza73m46A7Z"
      },
      "source": [
        "### Loop de Treinamento Customizado\n",
        "\n",
        "Usamos um loop customizado para calcular as perdas e aplicar os gradientes a cada época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUD5ETBO6Bfo",
        "outputId": "adf6e8a4-f094-4981-edd0-a4b3d9994326"
      },
      "outputs": [],
      "source": [
        "W_DATA = 1.0\n",
        "W_PHYSICS = 1.0\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "EPOCHS_ADAM = 200000\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, X_data, T_data, X_collocation):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_d = data_loss(model, X_data, T_data)\n",
        "        loss_p = physics_loss(\n",
        "            model, X_collocation[:, 0:1], X_collocation[:, 1:2], ALPHA\n",
        "        )\n",
        "        total_loss = W_DATA * loss_d + W_PHYSICS * loss_p\n",
        "\n",
        "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss_d, loss_p, total_loss\n",
        "\n",
        "\n",
        "history = []\n",
        "start_time = time.time()\n",
        "print(\"Iniciando Fase 1: Treinamento com Adam...\")\n",
        "\n",
        "for epoch in range(EPOCHS_ADAM):\n",
        "    loss_d, loss_p, total_loss = train_step(\n",
        "        pinn_model, X_train_tf, T_train_tf, X_collocation_tf\n",
        "    )\n",
        "\n",
        "    current_time = time.time() - start_time\n",
        "    history.append([epoch, loss_d, loss_p, total_loss])\n",
        "\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(\n",
        "            f\"Epoch {epoch+1:5d}, Loss_Data: {loss_d:.4e}, Loss_Physics: {loss_p:.4e}, Loss_Total: {total_loss:.4e}\"\n",
        "        )\n",
        "\n",
        "print(f\"Fase 1 (Adam) concluída em {current_time:.2f} segundos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPKnetIC868-"
      },
      "source": [
        "### Log de Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "x4xRxM0-9aso",
        "outputId": "9d3dda15-f651-468c-cf29-07166ab82eb1"
      },
      "outputs": [],
      "source": [
        "history = np.array(history)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history[:, 0], history[:, 1], label=\"Perda dos Dados\")\n",
        "plt.plot(history[:, 0], history[:, 2], label=\"Perda da Física\")\n",
        "plt.plot(history[:, 0], history[:, 3], label=\"Perda Total\")\n",
        "plt.xlabel(\"Épocas\")\n",
        "plt.ylabel(\"Perda\")\n",
        "plt.yscale(\"log\")\n",
        "plt.title(\"Log de Treinamento\")\n",
        "plt.legend()\n",
        "plt.savefig(\"../results/dirichlet_condition/training_log.png\", dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW9wPHPZ70A4",
        "outputId": "073d40ef-8b0b-4457-ebf8-d39c0a2581b5"
      },
      "outputs": [],
      "source": [
        "# Função auxiliar para definir os pesos a partir de um vetor 1D\n",
        "def set_weights(model, weights_1d):\n",
        "    \"\"\"\n",
        "    Desachata um vetor 1D de pesos e os atribui às variáveis do modelo.\n",
        "    Esta função corrige a lógica de unflattening.\n",
        "    \"\"\"\n",
        "    shapes = [v.shape for v in model.trainable_variables]\n",
        "    sizes = [tf.reduce_prod(s) for s in shapes]\n",
        "\n",
        "    start = 0\n",
        "    for i, (shape, size) in enumerate(zip(shapes, sizes)):\n",
        "        end = start + size\n",
        "        # Pega a fatia do vetor 1D e remodela para a forma original da camada\n",
        "        w = tf.reshape(weights_1d[start:end], shape)\n",
        "        model.trainable_variables[i].assign(w)\n",
        "        start = end\n",
        "\n",
        "\n",
        "def loss_and_grads_func(weights_1d):\n",
        "    \"\"\"\n",
        "    Calcula a perda e os gradientes para um dado vetor 1D de pesos.\n",
        "    \"\"\"\n",
        "    # Atribui os pesos do vetor 1D ao modelo.\n",
        "    set_weights(pinn_model, tf.cast(weights_1d, dtype=tf.float64))\n",
        "\n",
        "    # Calcula a perda com os novos pesos\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_d = data_loss(pinn_model, X_train_tf, T_train_tf)\n",
        "        loss_p = physics_loss(\n",
        "            pinn_model, X_collocation_tf[:, 0:1], X_collocation_tf[:, 1:2], ALPHA\n",
        "        )\n",
        "        total_loss = W_DATA * loss_d + W_PHYSICS * loss_p\n",
        "\n",
        "    # Calcula os gradientes\n",
        "    grads = tape.gradient(total_loss, pinn_model.trainable_variables)\n",
        "\n",
        "    # Achata a lista de gradientes em um único vetor 1D\n",
        "    grads_1d = tf.concat([tf.reshape(g, [-1]) for g in grads], axis=0)\n",
        "\n",
        "    return tf.cast(total_loss, tf.float64), tf.cast(grads_1d, tf.float64)\n",
        "\n",
        "\n",
        "# Execução da otimização L-BFGS\n",
        "\n",
        "# Pega os pesos atuais do modelo (após Adam) e os achata em um vetor 1D\n",
        "initial_weights = tf.concat(\n",
        "    [tf.reshape(v, [-1]) for v in pinn_model.trainable_variables], axis=0\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"\\nIniciando Fase 2: Refinamento com L-BFGS...\")\n",
        "\n",
        "# Chama o otimizador L-BFGS\n",
        "results = tfp.optimizer.lbfgs_minimize(\n",
        "    value_and_gradients_function=loss_and_grads_func,\n",
        "    initial_position=tf.cast(initial_weights, tf.float64),\n",
        "    num_correction_pairs=50,\n",
        "    max_iterations=2000,\n",
        "    tolerance=1e-10,\n",
        ")\n",
        "lbfgs_time = time.time() - start_time\n",
        "print(f\"Fase 2 (L-BFGS) concluída em {lbfgs_time:.2f} segundos.\")\n",
        "\n",
        "# Atribuição final dos pesos otimizados\n",
        "optimized_weights_1d = results.position\n",
        "set_weights(pinn_model, tf.cast(optimized_weights_1d, dtype=tf.float64))\n",
        "\n",
        "# Imprime a perda final após L-BFGS\n",
        "final_loss_d = data_loss(pinn_model, X_train_tf, T_train_tf)\n",
        "final_loss_p = physics_loss(\n",
        "    pinn_model, X_collocation_tf[:, 0:1], X_collocation_tf[:, 1:2], ALPHA\n",
        ")\n",
        "final_total_loss = W_DATA * final_loss_d + W_PHYSICS * final_loss_p\n",
        "\n",
        "print(\"\\nTreinamento concluído.\")\n",
        "print(\n",
        "    f\"Perda Final (após L-BFGS): Loss_Data: {final_loss_d:.4e}, Loss_Physics: {final_loss_p:.4e}, Loss_Total: {final_total_loss:.4e}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGTdAFFR803W"
      },
      "source": [
        "### Métricas de Avaliação\n",
        "\n",
        "Agora, usamos o modelo treinado para prever a temperatura em todo o domínio e comparamos com os dados de treinamento originais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkHaZXkP-jgw",
        "outputId": "ca1e202e-6ab2-45fb-d9e1-23b16b11f7f3"
      },
      "outputs": [],
      "source": [
        "# Fazer previsões nos mesmos pontos do DataFrame de treinamento\n",
        "T_pred = pinn_model.predict(X)\n",
        "\n",
        "# Calcular as métricas de erro\n",
        "mse = mean_squared_error(T, T_pred)\n",
        "mae = mean_absolute_error(T, T_pred)\n",
        "r2 = r2_score(T, T_pred)\n",
        "\n",
        "print(f\"Erro Quadrático Médio (MSE): {mse:.6f}\")\n",
        "print(f\"Erro Absoluto Médio (MAE):  {mae:.6f}\")\n",
        "print(f\"R2 Score:  {r2:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b48ZJhWT-nCL"
      },
      "source": [
        "### Visualização dos Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "nJuoz9JBB_Or",
        "outputId": "723c0e79-c6c0-4e5d-d82d-8755432a9a27"
      },
      "outputs": [],
      "source": [
        "t = np.unique(X[:, 0])\n",
        "x = np.unique(X[:, 1])\n",
        "\n",
        "Nt = len(t)\n",
        "Nx = len(x)\n",
        "\n",
        "U_sol = T.reshape([Nt, Nx])\n",
        "U_pred = T_pred.reshape([Nt, Nx])\n",
        "Err = np.abs(U_sol - U_pred)\n",
        "\n",
        "T_grid, X_grid = np.meshgrid(t, x)\n",
        "\n",
        "# Mapa de Calor U(x, t) - Valores Reais\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "ax = plt.gca()\n",
        "\n",
        "im = plt.pcolormesh(T_grid, X_grid, U_sol.T, cmap=\"coolwarm\", shading=\"gouraud\")\n",
        "cbar = fig.colorbar(im, ax=ax)\n",
        "cbar.set_label(\"Temperatura (U)\", fontsize=10)\n",
        "\n",
        "ax.set_title(\"Solução U(x, t)\")\n",
        "ax.set_xlabel(\"Tempo (t)\", fontsize=10)\n",
        "ax.set_ylabel(\"Posição (x)\", fontsize=10)\n",
        "\n",
        "plt.savefig(\"../results/dirichlet_condition/true_solution.png\", dpi=600)\n",
        "\n",
        "# Mapa de Calor U(x, t) - Valores Previstos\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "ax = plt.gca()\n",
        "\n",
        "im = plt.pcolormesh(T_grid, X_grid, U_pred.T, cmap=\"coolwarm\", shading=\"gouraud\")\n",
        "cbar = fig.colorbar(im, ax=ax)\n",
        "cbar.set_label(\"Temperatura (U)\", fontsize=10)\n",
        "\n",
        "ax.set_title(\"Predição U(x, t)\")\n",
        "ax.set_xlabel(\"Tempo (t)\", fontsize=10)\n",
        "ax.set_ylabel(\"Posição (x)\", fontsize=10)\n",
        "\n",
        "plt.savefig(\"../results/dirichlet_condition/prediction_solution.png\", dpi=600)\n",
        "\n",
        "# Mapa de Calor do Erro Err(x, t)\n",
        "\n",
        "plt.figure(figsize=(6, 3))\n",
        "ax = plt.gca()\n",
        "\n",
        "im = plt.pcolormesh(T_grid, X_grid, Err.T, cmap=\"coolwarm\", shading=\"gouraud\")\n",
        "cbar = fig.colorbar(im, ax=ax)\n",
        "cbar.set_label(\"Erro Absoluto\", fontsize=10)\n",
        "\n",
        "ax.set_title(\"Erro de Predição\")\n",
        "ax.set_xlabel(\"Tempo (t)\", fontsize=10)\n",
        "ax.set_ylabel(\"Posição (x)\", fontsize=10)\n",
        "\n",
        "plt.savefig(\"../results/dirichlet_condition/error.png\", dpi=600)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN8qRxnoltzJx6JZ76fC5dm",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
